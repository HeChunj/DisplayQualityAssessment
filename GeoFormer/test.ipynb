{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from PIL import Image\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import json\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def crop_image(image_path, centers, window_size, demo=\"\", data_type=\"\"):\n",
    "    \"\"\"\n",
    "    image_path: 图片路径\n",
    "    centers: 一系列中心坐标 (x, y) 的列表\n",
    "    window_size: 切割图块的大小（正方形的边长）\n",
    "    \"\"\"\n",
    "\n",
    "    # 检查图像路径是否存在\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Failed to load image: {image_path}\")\n",
    "\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    half_window = window_size // 2  # 窗口的一半\n",
    "\n",
    "    # 记录开始的时间\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 记录裁剪的图块的地址\n",
    "    cropped_image_paths = []\n",
    "\n",
    "    # 获取当前工作目录\n",
    "    current_directory = os.getcwd()\n",
    "\n",
    "    # 提取文件名（不带扩展名）\n",
    "    filename_without_ext = os.path.splitext(os.path.basename(image_path))[0]\n",
    "\n",
    "    result_dir = f'{current_directory}/croped_result_{demo}/{data_type}/{filename_without_ext}'\n",
    "\n",
    "    # 检查目录是否存在，如果不存在则创建\n",
    "    if not os.path.exists(result_dir):\n",
    "        os.makedirs(result_dir)\n",
    "    for i, (x, y) in enumerate(centers):\n",
    "        # 裁剪图块\n",
    "        cropped_image = crop_and_save(\n",
    "            image, x, y, half_window, width, height, i, result_dir)\n",
    "        cropped_image_paths.append(cropped_image)\n",
    "\n",
    "    # 记录结束的时间\n",
    "    end_time = time.time()\n",
    "    # print(f\"Time elapsed, crop img: {end_time - start_time} seconds\")\n",
    "\n",
    "    return cropped_image_paths\n",
    "\n",
    "\n",
    "def crop_and_save(image, x, y, half_window, width, height, i, result_dir):\n",
    "\n",
    "    # 确定裁剪区域的左上角和右下角\n",
    "    left = max(0, x - half_window)\n",
    "    top = max(0, y - half_window)\n",
    "    right = min(width, x + half_window)\n",
    "    bottom = min(height, y + half_window)\n",
    "\n",
    "    left = round(left)\n",
    "    top = round(top)\n",
    "    right = round(right)\n",
    "    bottom = round(bottom)\n",
    "\n",
    "    # 确保裁剪区域在图像边界内\n",
    "    if left < 0:\n",
    "        left = 0\n",
    "    if top < 0:\n",
    "        top = 0\n",
    "    if right > width:\n",
    "        right = width\n",
    "    if bottom > height:\n",
    "        bottom = height\n",
    "\n",
    "    # 裁剪图块\n",
    "    cropped_image = image[top:bottom, left:right]\n",
    "\n",
    "    # 保存裁剪的图块的坐标信息到json文件\n",
    "    json_path = os.path.join(result_dir, f\"cropped_image_coordinate.json\")\n",
    "    res = {}\n",
    "    res[\"coordinates\"] = []\n",
    "    res[\"coordinates\"].append({\n",
    "        \"cx\": x,\n",
    "        \"cy\": y,\n",
    "        \"left\": left,\n",
    "        \"top\": top,\n",
    "        \"right\": right,\n",
    "        \"bottom\": bottom\n",
    "    })\n",
    "    if os.path.exists(json_path):\n",
    "        # 删除已经存在的json文件\n",
    "        # os.remove(json_path)\n",
    "        with open(json_path, 'r') as json_file:\n",
    "            data = json.load(json_file)\n",
    "        res['coordinates'] = res['coordinates'] + data['coordinates']\n",
    "    with open(json_path, 'w') as json_file:\n",
    "        json.dump(res, json_file, indent=4)\n",
    "\n",
    "    # 保存裁剪的图块到指定目录\n",
    "    save_path = os.path.join(result_dir, f\"cropped_image_{i}.png\")\n",
    "    cv2.imwrite(save_path, cropped_image)\n",
    "\n",
    "    return save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hechunjiang/software/anaconda3/envs/GeoFormer/lib/python3.8/site-packages/kornia/feature/lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hechunjiang/gradio/GeoFormer\n",
      "Initialize GeoFormer_geoformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3636172/2776161142.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt_dict = torch.load(ckpt, map_location=torch.device('cpu'))\n"
     ]
    }
   ],
   "source": [
    "from argparse import Namespace\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import rawpy\n",
    "import os\n",
    "\n",
    "from model.loftr_src.loftr.utils.cvpr_ds_config import default_cfg\n",
    "from model.full_model import GeoFormer as GeoFormer_\n",
    "\n",
    "from eval_tool.immatch.utils.data_io import load_gray_scale_tensor_cv\n",
    "from model.geo_config import default_cfg as geoformer_cfg\n",
    "\n",
    "\n",
    "class GeoFormer():\n",
    "    def __init__(self, imsize, match_threshold, no_match_upscale=False, ckpt=None, device='cuda'):\n",
    "\n",
    "        self.device = device\n",
    "        self.imsize = imsize\n",
    "        self.match_threshold = match_threshold\n",
    "        self.no_match_upscale = no_match_upscale\n",
    "\n",
    "        # Load model\n",
    "        conf = dict(default_cfg)\n",
    "        conf['match_coarse']['thr'] = self.match_threshold\n",
    "        geoformer_cfg['coarse_thr'] = self.match_threshold\n",
    "        self.model = GeoFormer_(conf)\n",
    "        ckpt_dict = torch.load(ckpt, map_location=torch.device('cpu'))\n",
    "        if 'state_dict' in ckpt_dict:\n",
    "            ckpt_dict = ckpt_dict['state_dict']\n",
    "        self.model.load_state_dict(ckpt_dict, strict=False)\n",
    "        self.model = self.model.eval().to(self.device)\n",
    "\n",
    "        # Name the method\n",
    "        self.ckpt_name = ckpt.split('/')[-1].split('.')[0]\n",
    "        self.name = f'GeoFormer_{self.ckpt_name}'\n",
    "        if self.no_match_upscale:\n",
    "            self.name += '_noms'\n",
    "        print(f'Initialize {self.name}')\n",
    "\n",
    "    def change_deivce(self, device):\n",
    "        self.device = device\n",
    "        self.model.to(device)\n",
    "\n",
    "    def load_im(self, im_path, enhanced=False):\n",
    "        return load_gray_scale_tensor_cv(\n",
    "            im_path, self.device, imsize=self.imsize, dfactor=8, enhanced=enhanced, value_to_scale=min\n",
    "        )\n",
    "\n",
    "    def match_inputs_(self, gray1, gray2, is_draw=False):\n",
    "\n",
    "        batch = {'image0': gray1, 'image1': gray2}\n",
    "        with torch.no_grad():\n",
    "            batch = self.model(batch)\n",
    "        kpts1 = batch['mkpts0_f'].cpu().numpy()\n",
    "        kpts2 = batch['mkpts1_f'].cpu().numpy()\n",
    "\n",
    "        def draw():\n",
    "            import matplotlib.pyplot as plt\n",
    "            import cv2\n",
    "            import numpy as np\n",
    "            plt.figure(dpi=500)\n",
    "            kp0 = kpts1\n",
    "            kp1 = kpts2\n",
    "            # if len(kp0) > 0:\n",
    "            kp0 = [cv2.KeyPoint(int(k[0]), int(k[1]), 30) for k in kp0]\n",
    "            kp1 = [cv2.KeyPoint(int(k[0]), int(k[1]), 30) for k in kp1]\n",
    "            matches = [cv2.DMatch(_trainIdx=i, _queryIdx=i, _distance=1, _imgIdx=-1) for i in\n",
    "                       range(len(kp0))]\n",
    "\n",
    "            show = cv2.drawMatches((gray1.cpu()[0][0].numpy() * 255).astype(np.uint8), kp0,\n",
    "                                   (gray2.cpu()[0][0].numpy() *\n",
    "                                    255).astype(np.uint8), kp1, matches,\n",
    "                                   None)\n",
    "            plt.imshow(show)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "        if is_draw:\n",
    "            draw()\n",
    "        scores = batch['mconf'].cpu().numpy()\n",
    "        matches = np.concatenate([kpts1, kpts2], axis=1)\n",
    "        return matches, kpts1, kpts2, scores\n",
    "\n",
    "    def match_pairs(self, im1_path, im2_path, cpu=False, is_draw=False):\n",
    "        torch.cuda.empty_cache()\n",
    "        tmp_device = self.device\n",
    "        if cpu:\n",
    "            self.change_deivce('cpu')\n",
    "\n",
    "        gray1, sc1 = self.load_im(im1_path)\n",
    "        gray2, sc2 = self.load_im(im2_path)\n",
    "\n",
    "        upscale = np.array([sc1 + sc2])\n",
    "        matches, kpts1, kpts2, scores = self.match_inputs_(\n",
    "            gray1, gray2, is_draw)\n",
    "\n",
    "        if self.no_match_upscale:\n",
    "            return matches, kpts1, kpts2, scores, upscale.squeeze(0)\n",
    "\n",
    "        # Upscale matches &  kpts\n",
    "        matches = upscale * matches\n",
    "        kpts1 = sc1 * kpts1\n",
    "        kpts2 = sc2 * kpts2\n",
    "\n",
    "        if cpu:\n",
    "            self.change_deivce(tmp_device)\n",
    "\n",
    "        return matches, kpts1, kpts2, scores\n",
    "\n",
    "\n",
    "g = GeoFormer(640, 0.9, no_match_upscale=False,\n",
    "              ckpt='saved_ckpt/geoformer.ckpt', device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_homography_res(img1_path, img2_path, kpts1, kpts2, matches, is_draw=False):\n",
    "    if len(matches) < 4:\n",
    "        return None\n",
    "\n",
    "    img1_color = cv2.imread(img1_path)\n",
    "    img2_color = cv2.imread(img2_path)\n",
    "\n",
    "    src_pts = np.float32(matches[:, :2]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32(matches[:, 2:]).reshape(-1, 1, 2)\n",
    "\n",
    "    matrix, inliers = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "    height, width = img2_color.shape[:2]\n",
    "\n",
    "    aligned_img1_color = cv2.warpPerspective(\n",
    "        img1_color, matrix, (width, height))\n",
    "\n",
    "    if is_draw:\n",
    "        plt.figure(dpi=500)\n",
    "\n",
    "        # 示例关键点和图像\n",
    "        kp0 = [cv2.KeyPoint(int(k[0]), int(k[1]), 30) for k in kpts2]\n",
    "        kp1 = [cv2.KeyPoint(int(k[0]), int(k[1]), 30) for k in kpts2]\n",
    "        matches = [cv2.DMatch(_trainIdx=i, _queryIdx=i,\n",
    "                              _distance=1, _imgIdx=-1) for i in range(len(kp0))]\n",
    "\n",
    "        # 转换图像为 RGB 格式\n",
    "        aligned_img1_rgb = cv2.cvtColor(aligned_img1_color, cv2.COLOR_BGR2RGB)\n",
    "        img2_rgb = cv2.cvtColor(img2_color, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 创建拼接图像\n",
    "        h1, w1 = aligned_img1_rgb.shape[:2]\n",
    "        h2, w2 = img2_rgb.shape[:2]\n",
    "        canvas = np.zeros((max(h1, h2), w1 + w2, 3), dtype=np.uint8)\n",
    "        canvas[:h1, :w1] = aligned_img1_rgb\n",
    "        canvas[:h2, w1:w1 + w2] = img2_rgb\n",
    "\n",
    "        # 绘制匹配点和随机颜色连线\n",
    "        for match in matches:\n",
    "            pt1 = (int(kp0[match.queryIdx].pt[0]),\n",
    "                   int(kp0[match.queryIdx].pt[1]))\n",
    "            pt2 = (int(kp1[match.trainIdx].pt[0]) +\n",
    "                   w1, int(kp1[match.trainIdx].pt[1]))\n",
    "            random_color = tuple(np.random.randint(0, 256, 3).tolist())\n",
    "            cv2.line(canvas, pt1, pt2, color=random_color, thickness=2)\n",
    "            cv2.circle(canvas, pt1, radius=10,\n",
    "                       color=random_color, thickness=-1)\n",
    "            cv2.circle(canvas, pt2, radius=10,\n",
    "                       color=random_color, thickness=-1)\n",
    "\n",
    "        # 显示结果\n",
    "        print(\"仿射变换后的匹配结果：\")\n",
    "        plt.imshow(canvas)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    return cv2.cvtColor(aligned_img1_color, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 17\u001b[0m\n\u001b[1;32m      5\u001b[0m img2_path_list \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/hechunjiang/gradio/样品1 LG 65UF8580/华为P50手机采集图像/样品1采集图像/\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/hechunjiang/gradio/样品2 SONY 43吋/华为P50手机采集图像/\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/hechunjiang/gradio/样品7 海信 27G7K-PRO/华为P50采集图像/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m ]\n\u001b[1;32m     15\u001b[0m all_croped_image_counts \u001b[38;5;241m=\u001b[39m [[] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(demo_list))]\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, (demo, image2_path) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(demo_list, img2_path_list):\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m22\u001b[39m):\n\u001b[1;32m     19\u001b[0m         img1_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/hechunjiang/gradio/监视器采集图像/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "demo_list = [\"LG\", \"SONY\", \"AMAZON\", \"SKYWORTH\", \"KTC\", \"REDMAGIC\", \"HISENSE\"]\n",
    "\n",
    "img2_path_list = [\n",
    "    \"/home/hechunjiang/gradio/样品1 LG 65UF8580/华为P50手机采集图像/样品1采集图像/\",\n",
    "    \"/home/hechunjiang/gradio/样品2 SONY 43吋/华为P50手机采集图像/\",\n",
    "    \"/home/hechunjiang/gradio/样品3 亚马逊 43吋/华为P50手机采集图像/\",\n",
    "    \"/home/hechunjiang/gradio/样品4 创维 F32D80U/华为P50采集图像/\",\n",
    "    \"/home/hechunjiang/gradio/样品5 KTC M27P20P/华为P50采集图像/\",\n",
    "    \"/home/hechunjiang/gradio/样品6 红魔 GM001S/华为P50采集图像/\",\n",
    "    \"/home/hechunjiang/gradio/样品7 海信 27G7K-PRO/华为P50采集图像/\"\n",
    "]\n",
    "\n",
    "all_croped_image_counts = [[] for _ in range(len(demo_list))]\n",
    "\n",
    "for idx, (demo, image2_path) in enumerate(zip(demo_list, img2_path_list)):\n",
    "    for i in range(1, 22):\n",
    "        img1_path = f\"/home/hechunjiang/gradio/监视器采集图像/{i}.jpg\"\n",
    "        img2_path = f\"{image2_path}{i}.jpg\"\n",
    "\n",
    "        matches, kpts1, kpts2, scores = g.match_pairs(\n",
    "            img1_path, img2_path, is_draw=False)\n",
    "        res = {\"matches\": matches.tolist(), \"kpts1\": kpts1.tolist(),\n",
    "               \"kpts2\": kpts2.tolist(), \"scores\": scores.tolist()}\n",
    "\n",
    "        # 将monitor向样品对齐\n",
    "        aligned_img = get_homography_res(\n",
    "            img1_path, img2_path, kpts1, kpts2, matches, is_draw=False)\n",
    "\n",
    "        if aligned_img is None:\n",
    "            print(f\"{demo}下的第{i}张图 : 匹配点数过少\")\n",
    "            continue\n",
    "\n",
    "        # 保存aligned_img\n",
    "        save_path = f\"/home/hechunjiang/gradio/aligned_imgs/{demo}/{i}.jpg\"\n",
    "        if not os.path.exists(os.path.dirname(save_path)):\n",
    "            os.makedirs(os.path.dirname(save_path))\n",
    "\n",
    "        cv2.imwrite(save_path, cv2.cvtColor(aligned_img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        croped_image_path1 = crop_image(\n",
    "            save_path, res['kpts2'], 300, demo, \"finetune_ref\")\n",
    "        croped_image_path2 = crop_image(\n",
    "            img2_path, res['kpts2'], 300, demo, \"finetune_dst\")\n",
    "        print(f\"{demo} : {i}.png done, num of croped_image: {len(croped_image_path1)}\")\n",
    "        all_croped_image_counts[idx].append(len(croped_image_path1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeoFormer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
